{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 심층 신경망이 부딪힌 한계 - 사라지는 기울기\n",
    "### 8.2 심층 신경망 학습의 돌파구 - 연결강도 초기화\n",
    "### 8.3 활성화 함수의 다양화\n",
    "### 8.4 최적화 기법 - 경사하강법의 문제와 개선\n",
    "### 8.5 다양한 최적화 기법 소개\n",
    "### 8.6 텐서플로우 시작\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✔머신러닝과 딥러닝의 프레임워크 : 텐서플로우 , 데아노, 파이토치, 케라스, 사이킷런, NLTK\n",
    "\n",
    "✔미국 국립표준 연구소National Institute of Standards and Technology에서는 손으로 쓴 숫자들로 이루어진 글씨 데이터를 스캐닝하여 다양한 화상처리 시스템에서 사용하기 위하여 제공하고 있는데 이 데이터가 바로 MNISTModified National Institute of Standards and Technology 데이터베이스\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n",
      "x_train 데이터의 형태: (60000, 28, 28)\n",
      "x_train[0] 데이터의 형태: (28, 28)\n",
      "y_train 데이터의 형태: (60000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = tf.keras.datasets.mnist # MNIST 이미지를 제공하는 케라스라는 모듈을 포함하고 있는데 이 이미지 셋을 가져온다.\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('x_train 데이터의 형태:', x_train.shape)\n",
    "print('x_train[0] 데이터의 형태:', x_train[0].shape)\n",
    "print('y_train 데이터의 형태:',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0\n",
      "   0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"
     ]
    }
   ],
   "source": [
    "num = x_train[0]\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        print('{:4d}'.format(num[i][j]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train의 첫번째 데이터의 형태가 (28,28)크기의 데이터 \n",
    "최소 0 최댓값 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19514595280>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(num, cmap='Greys', interpolation='nearest')\n",
    "#회색조 이미지로 만들어 이 배열의 의미 파악\n",
    "#이 데이터의 형태가 기울어진 5와 비슷\n",
    "#이제 다음과 같은 방법으로 부드럽게 보간된 회색조 이미지로 만들어 이 배열의 의미를 이해하자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[0] = 5\n"
     ]
    }
   ],
   "source": [
    "print('y_train[0] =', y_train[0])\n",
    "#이 배열 데이터는 숫자 5의 손글씨와 비슷한 이미지 임을 알 수 있는데, \n",
    "# 이 이미지의 의미는 다음과 같이 y_train[0] 배열에 5라고 레이블링 되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train[0] 배열에 5라고 레이블링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.8 keras로 순차 심층신경망 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.9335 ETA: 0s - loss: - 2s 918us/step - loss: 0.2258 - accuracy: 0.9344\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 2s 896us/step - loss: 0.0924 - accuracy: 0.97240s - loss: 0.0935 - accuracy: \n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 2s 901us/step - loss: 0.0605 - accuracy: 0.9817\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 2s 880us/step - loss: 0.0429 - accuracy: 0.98630s - loss: 0.0417 - accu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19514039d30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255, x_test / 255  \n",
    "# 입력값 정규화 : 원래 입력값의 범위 0~255를 0에서 1사이의 값으로 조정하는 정규화 단계(그래서 255로 나누는 것)\n",
    "\n",
    "model = keras.models.Sequential( [#Sequential모델을 사용\n",
    "    keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    keras.layers.Dense(256, activation = 'relu'), #은닉층 활성화 하는 함수 지정(RELU)\n",
    "    keras.layers.Dense(10, activation = 'softmax'),#출력값을 확률값으로 변환하는 함수 지정(softmax)\n",
    "])\n",
    "\n",
    "# 학습을 위한 최적화 함수, 손실 함수등을 가진 모델을 컴파일\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs = 4)\n",
    "\n",
    "#노드와 구조 손쉽게 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👍이제 MNIST 데이터를 사용하여 우리가 할 일\n",
    "\n",
    "- 6만 개의 이미지로 이루어진 x_train 데이터를 심층 신경망 모델에 넣어서 \n",
    "- y_train 데이터의 숫자로 인식하도록 학습을 시키는 일\n",
    "- 이 때 노드의 활성화 함수, 학습을 위한 최적화 함수, 손실 함수, 측정방법을 정의하는 일\n",
    "- 1만 개의 이미지로 이루어진 x_test 데이터를 학습을 마친 모델의 입력으로 넣어서 이 모델의 정확도를 알아보는 일\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.9 인공신경망을 최적화 시키자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "#만든 신경망 모델이 어떤 형태를 가지고 있으며, 몇 개의 파라미터를 훈련시켜서 만든 모델인가를 model.summary() 함수를 통해서 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망 모델의 학습 결과 :\n",
      "313/313 [==============================] - 0s 720us/step - loss: 0.0729 - accuracy: 0.9781\n",
      "test 데이터의 손실값 0.07285822927951813 test 데이터의 정확도 0.9781000018119812\n"
     ]
    }
   ],
   "source": [
    "print('신경망 모델의 학습 결과 :')\n",
    "eval_loss, eval_acc = model.evaluate(x_test, y_test)\n",
    "print('test 데이터의 손실값', eval_loss, 'test 데이터의 정확도', eval_acc)\n",
    "#이제까지 학습에 사용하지 않은 1만 개의 숫자 이미지가 있는 x_test를 이 모델에 넣어서 y_test와 비교\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.10 소프트맥스 함수와 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망의 예측값 : [0.5 4.1 2.5 5.6 1.2]\n",
      "소프트맥스 함수의 출력 : [0.00473882 0.17343248 0.03501541 0.77727047 0.00954281]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(a):    \n",
    "    exp_of_a = np.exp(a)       # 각각의 지수 함수\n",
    "    sum_exp = np.sum(exp_of_a) # 지수 함수값의 합\n",
    "    y = exp_of_a / sum_exp\n",
    "    return y\n",
    "\n",
    "a = np.array([0.5, 4.1, 2.5, 5.6, 1.2])\n",
    "print('신경망의 예측값 :', a)\n",
    "print('소프트맥스 함수의 출력 :', softmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#0       1    2    3    4 \n",
    "#[0.5  4.1  2.5  5.6  1.2] #최종 노트 출력은 가중치 값\n",
    "# -------------------\n",
    "# 소프트 맥스 함수 \n",
    "# -------------------\n",
    "# 0.0047 0.1734 0.0350 0.7772 0.0095  #숫자 0일 확률 , 숫자 1일 확률 ,숫자 2일 확률 ,숫자 3일 확률 , 숫자 4일 확률 \n",
    "# 가중치 값을 가진 벡터를 0에서 1사이의 클래스별 확률값으로 변환하기 위해서 사용하는 함수가\n",
    "#  바로 소프트맥스softmax 함수\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소프트맥스 함수의 최댓값 : 0.7772704668966948\n"
     ]
    }
   ],
   "source": [
    "print('소프트맥스 함수의 최댓값 :', np.max(softmax(a)))\n",
    "\n",
    "#소프트맥스 함수는 최대값을 더욱 활성화하고 작은 값을 억제하는 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망의 예측값 : [ 1.   8.2  5.  11.2  2.4]\n",
      "소프트맥스 함수의 출력 : [3.53328547e-05 4.73259126e-02 1.92910850e-03 9.50566364e-01\n",
      " 1.43281791e-04]\n",
      "소프트맥스 함수의 최댓값 : 0.9505663642857384\n"
     ]
    }
   ],
   "source": [
    "# 소프트맥스 함수의 입력값을 두 배로 증가시켜보자\n",
    "a = np.array([0.5, 4.1, 2.5, 5.6, 1.2]) * 2\n",
    "print('신경망의 예측값 :', a)\n",
    "print('소프트맥스 함수의 출력 :', softmax(a))\n",
    "print('소프트맥스 함수의 최댓값 :', np.max(softmax(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.11 원-핫 인코딩과 평균제곱 오차\n",
    "✔소프트맥스 함수의 출력값과 정답과의 차이를 구하는 방법\n",
    "\n",
    "✔이를 위하여 원-핫 인코딩one-hot encoding 기법의 필요성에 대하여 알아보자\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👍원-핫 인코딩은 다음의 두 단계 과정을 통해서 간단하게 구현\n",
    "\n",
    "- 각 레이블에 고유의 인덱스를 부여\n",
    "\n",
    "- 표현하고자 하는 레이블의 인덱스 위치에 1을 부여하고, 나머지 인덱스의 값으로 0을 부여\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩할 원본 데이터 [0 1 2 3 4]\n",
      "원-핫 인코딩된 데이터 :\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "data = np.array([0, 1, 2, 3, 4])  # 수치 데이터 0에서 4까지의 값\n",
    "print('인코딩할 원본 데이터',data)\n",
    "encoded = to_categorical(data)    # 원-핫 인코딩된 범주형 데이터 생성\n",
    "print('원-핫 인코딩된 데이터 :')\n",
    "print(encoded)\n",
    "\n",
    "# from keras.utils import to_categorical 대신\n",
    "# from tensorflow.keras.utils import to_categorical을 사용하면 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat과 target과의 오차 : 0.016201599999999997\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 정답 3이 인코딩된 target과 신경망의 예측값 y_hat이 있다고 가정하자\n",
    "target = np.array([0, 0, 0, 1, 0]) #레이블 3은 원-핫 인코딩되어 [0, 0, 0, 1, 0]의 형태로 변환 \n",
    "y_hat = np.array([0.005, 0.173, 0.035, 0.777, 0.01])\n",
    "\n",
    "def mse(y, t):   # 평균제곱오차\n",
    "    return ((y-t)**2).mean()\n",
    "\n",
    "print('y_hat과 target과의 오차 :', mse(y_hat, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_y_hat과 target과의 오차 : 0.25564\n"
     ]
    }
   ],
   "source": [
    "# 정답에서 많이 벗어난 other_y_hat 추정치\n",
    "other_y_hat = np.array([0.2, 0.3, 0.4, 0.01, 0.09])\n",
    "# other_y_hat 추정치와 정답과의 오차를 알아보자 \n",
    "print('other_y_hat과 target과의 오차 :', mse( other_y_hat, target ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.12 평균제곱 오차와 교차 엔트로피 오차\n",
    "\n",
    "손실함수(신경망의 데이터 분석결과(성능)의 나쁨 정도)\n",
    "- cee : 교차 엔트로피는 평균제곱오차와는 달리 오직 실제 정답과의 오차만을 파악하는 손실함수\n",
    "- mse :  y는 신경망의 출력층 결과 리스트이고 t는 실제 데이터의 정답을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat1과의 cee : 0.60\n",
      "y_hat2과의 cee : 4.61\n",
      "두 값의 비 : 7.70\n",
      "y_hat1과의 mse : 0.12\n",
      "y_hat2과의 mse : 0.60\n",
      "두 값의 비 : 4.93\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mse(y, t):   # 평균제곱오차\n",
    "    return ((y-t)**2).mean()\n",
    "    \n",
    "# 교차 엔트로피 함수를 에러 함수로 사용해 보도록 하자\n",
    "def cee(y, t):\n",
    "   delta = 1e-7\n",
    "   return -np.sum(t * np.log(y + delta))\n",
    "\n",
    "t = np.array([0, 0, 1])\n",
    "y_hat1 = np.array([0.4, 0.05, 0.55])\n",
    "y_hat2 = np.array([0.9, 0.09, 0.01])\n",
    "\n",
    "# y_hat 추정치와 정답과의 오차를 알아보자\n",
    "print('y_hat1과의 cee : {:.2f}'.format(cee(y_hat1, t)))\n",
    "print('y_hat2과의 cee : {:.2f}'.format(cee(y_hat2, t)))\n",
    "print('두 값의 비 : {:.2f}'.format(cee(y_hat2, t)/cee(y_hat1, t)))\n",
    "\n",
    "# y_hat 추정치와 정답과의 오차를 알아보자\n",
    "print('y_hat1과의 mse : {:.2f}'.format(mse(y_hat1, t)))\n",
    "print('y_hat2과의 mse : {:.2f}'.format(mse(y_hat2, t)))\n",
    "print('두 값의 비 : {:.2f}'.format(mse(y_hat2, t)/mse(y_hat1, t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.13 정규화와 표준화, 배치 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'num of rooms')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "yr = np.array([15, 30, 23, 5, 9, 43, 33, 29, 3, 56]) \n",
    "# 데이터를 살펴보면 주택의 건축연도는 3년에서 56년으로 범위가 크다.\n",
    "n_rooms = np.array([2, 4, 3, 4, 4, 3, 3, 1, 1, 2])\n",
    "# 방의 수 \n",
    "min_max_scaler = MinMaxScaler()\n",
    "yr_norm = min_max_scaler.fit_transform(yr[:, np.newaxis])\n",
    "n_rooms_norm = min_max_scaler.fit_transform(n_rooms[:, np.newaxis])\n",
    "\n",
    "#위의 경우를 그래프로 그려보면 아래와 같이 나타날 것\n",
    "#이 경우 기계 학습이 예측을 할 때 방의 개수보다는 더 큰 스케일을가지는 건축연도에 의하여 예측값이 좌지우지될 가능성이 큼\n",
    "# sklearn의preprocessing 하위 모듈에 있는 min_max_scaler()를 사용하여 방의 수와 연도를\n",
    "# 0에서 1사이의 값으로 스케일링하고 시각화 시킨 것\n",
    "\n",
    "plt.scatter(yr_norm, n_rooms_norm, c='red')\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.xlabel('year')              \n",
    "plt.ylabel('num of rooms')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.14 확률적 경사 하강법과 배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.15 더 깊은 층으로 정확도를 높여보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cdcb9daa5a03e1722fcc0d4a4ce3ae98b7da86b84924a344b8688728b50fac5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
